[
  {
    "objectID": "about/TeresaLardo.html",
    "href": "about/TeresaLardo.html",
    "title": "Teresa (Peri) Lardo",
    "section": "",
    "text": "I spent the last 8 years working for an educational software and services company. My bachelor’s degree is in English, with a concentration in creative writing."
  },
  {
    "objectID": "about/TeresaLardo.html#r-experience",
    "href": "about/TeresaLardo.html#r-experience",
    "title": "Teresa (Peri) Lardo",
    "section": "R experience",
    "text": "R experience\nI have almost no experience in R, but studied some R basics for a few weeks before entering the DACSS program."
  },
  {
    "objectID": "about/TeresaLardo.html#hometown",
    "href": "about/TeresaLardo.html#hometown",
    "title": "Teresa (Peri) Lardo",
    "section": "Hometown",
    "text": "Hometown\nI’m currently living in Medford, Mass., with a partner, our two roommates, and a cat who is, of course, the most important member of the household."
  },
  {
    "objectID": "about/TeresaLardo.html#hobbies",
    "href": "about/TeresaLardo.html#hobbies",
    "title": "Teresa (Peri) Lardo",
    "section": "Hobbies",
    "text": "Hobbies\nI enjoy writing poetry, making beaded jewelry, and painting watercolor birds. I love learning and also take non-university classes for fun when I can; as I begin the DACSS program, I am finishing up a year-long course on tropical astrology as well as a short Atlas Obscura course on fairy tale writing."
  },
  {
    "objectID": "about/TeresaLardo.html#fun-fact",
    "href": "about/TeresaLardo.html#fun-fact",
    "title": "Teresa (Peri) Lardo",
    "section": "Fun fact",
    "text": "Fun fact\nYour mileage may vary on how fun this fact is, but I only started drinking coffee because of a series of murder mystery novels set in the Scottish Highlands. The detective in the series is constantly visiting townsfolk and being served tea or coffee, and I envied the cozy vibe while I listened to the audiobooks at work, so I started paying visits to the office coffee machine."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Contributors",
    "section": "",
    "text": "Find out more about our DACSS students who contributed to the blog.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTeresa (Peri) Lardo\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DACSS 601: Data Science Fundamentals Spring-2023",
    "section": "",
    "text": "The blog posts here are contributed by students enrolled in DACSS 601, Fundamentals of Data Science. The course provides students with an introduction to R and the tidyverse, scientific publishing, and collaboration through GitHub, building a foundation for future coursework. Students also are introduced to general data management and data wrangling skills, with an emphasis on best practice workflows and tidy data management.\n\n\n\n\n\n\n\n\n\n\nChallenge 7: AirBnB Visualizations\n\n\n\n\n\n\n\nchallenge_7\n\n\nTeresa Lardo\n\n\nair_bnb\n\n\n\n\nVisualizing Multiple Dimensions\n\n\n\n\n\n\nApr 17, 2023\n\n\nTeresa Lardo\n\n\n\n\n\n\n\n\nFinal Project Assignment#1: Teresa Lardo\n\n\n\n\n\n\n\nfinal_Project_assignment_1\n\n\nfinal_project_data_description\n\n\nTeresa Lardo\n\n\nBigfoot Reports\n\n\n\n\nProject & Data Description\n\n\n\n\n\n\nApr 12, 2023\n\n\nTeresa Lardo\n\n\n\n\n\n\n\n\nChallenge 6: ADR Visualizations for Hotels\n\n\n\n\n\n\n\nchallenge_6\n\n\nTeresa Lardo\n\n\nhotel_bookings\n\n\n\n\nVisualizing Time and Relationships\n\n\n\n\n\n\nApr 5, 2023\n\n\nTeresa Lardo\n\n\n\n\n\n\n\n\nChallenge 5: Public School Characteristics\n\n\n\n\n\n\n\nchallenge_5\n\n\nTeresa Lardo\n\n\npublic_schools\n\n\n\n\nCreating uni- and bivariate visualizations\n\n\n\n\n\n\nMar 29, 2023\n\n\nTeresa Lardo\n\n\n\n\n\n\n\n\nChallenge 4: Hotel Bookings\n\n\n\n\n\n\n\nchallenge_4\n\n\nTeresa Lardo\n\n\nhotel_bookings\n\n\n\n\nUsing mutate and lubridate to consolidate data\n\n\n\n\n\n\nMar 21, 2023\n\n\nTeresa Lardo\n\n\n\n\n\n\n\n\nChallenge 2\n\n\n\n\n\n\n\nchallenge_2\n\n\nTeresa Lardo\n\n\nhotel_bookings\n\n\n\n\nGrouping a dataset on hotel bookings and providing summary statistics\n\n\n\n\n\n\nFeb 22, 2023\n\n\nTeresa Lardo\n\n\n\n\n\n\n\n\nChallenge 1: Railroad Workers 2012\n\n\n\n\n\n\n\nchallenge_1\n\n\nTeresa Lardo\n\n\ndataset\n\n\n\n\n\n\n\n\n\n\n\nFeb 21, 2023\n\n\nTeresa Lardo\n\n\n\n\n\n\n\n\nChallenge 3: Animal Weights\n\n\n\n\n\n\n\nchallenge_3\n\n\nanimal_weights\n\n\nTeresa Lardo\n\n\n\n\nTidy Data: Pivoting\n\n\n\n\n\n\nAug 17, 2022\n\n\nTeresa Lardo\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/TeresaLardo_Challenge1.html",
    "href": "posts/TeresaLardo_Challenge1.html",
    "title": "Challenge 1: Railroad Workers 2012",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\nknitr::opts_chunk$set(echo = TRUE)\nlibrary(readr)\nlibrary(dplyr)\nrailroad <- read_csv(\"_data/railroad_2012_clean_county.csv\", show_col_types = FALSE)"
  },
  {
    "objectID": "posts/TeresaLardo_Challenge1.html#choo-choo-all-aboard",
    "href": "posts/TeresaLardo_Challenge1.html#choo-choo-all-aboard",
    "title": "Challenge 1: Railroad Workers 2012",
    "section": "Choo-choo, all aboard!",
    "text": "Choo-choo, all aboard!\nThis data set shows the total number of railroad employees per county in the United States in the year 2012. Running the head() function displays the first 6 rows of the data set.\n\n\nCode\nhead(railroad)\n\n\n# A tibble: 6 × 3\n  state county               total_employees\n  <chr> <chr>                          <dbl>\n1 AE    APO                                2\n2 AK    ANCHORAGE                          7\n3 AK    FAIRBANKS NORTH STAR               2\n4 AK    JUNEAU                             3\n5 AK    MATANUSKA-SUSITNA                  2\n6 AK    SITKA                              1\n\n\n\n\nCode\ndim(railroad)\n\n\n[1] 2930    3\n\n\nThe dim() functions shows us that the data set contains 2930 rows (2930 counties) and 3 columns (state, county, and total_employees).\nThe very first item lists a state code of “AE” and a county of “APO” with 2 employees for the year 2012. Since this is different from the state codes and county names that follow, I want to clarify that this is for overseas military. Besides “AE,” the other overseas military “state” abbreviations are AP and AA. Let’s check for all of these state codes in the data set.\n\n\nCode\n# Filter the state column through a vector of overseas military state codes\noverseas <- railroad %>% \n  filter(\n    state %in% c(\"AA\", \"AE\", \"AP\")\n  )\noverseas\n\n\n# A tibble: 2 × 3\n  state county total_employees\n  <chr> <chr>            <dbl>\n1 AE    APO                  2\n2 AP    APO                  1\n\n\nFiltering the original data set by states in a vector of military overseas abbreviations shows that only Armed Forces Europe (AE) and Armed Forces Pacific (AP) appear in this data set; Armed Forces the Americas (AA) does not.\n\n\nCode\n# How many unique values are in the state column?\nrailroad %>% \n  select(state) %>% \n  n_distinct(.)\n\n\n[1] 53\n\n\nSo apparently there are 53 unique values under the ‘state’ column. There’s 50 states, and the two overseas military codes we found before make 52. What’s the other one?\n\n\nCode\nunique(railroad$state)\n\n\n [1] \"AE\" \"AK\" \"AL\" \"AP\" \"AR\" \"AZ\" \"CA\" \"CO\" \"CT\" \"DC\" \"DE\" \"FL\" \"GA\" \"HI\" \"IA\"\n[16] \"ID\" \"IL\" \"IN\" \"KS\" \"KY\" \"LA\" \"MA\" \"MD\" \"ME\" \"MI\" \"MN\" \"MO\" \"MS\" \"MT\" \"NC\"\n[31] \"ND\" \"NE\" \"NH\" \"NJ\" \"NM\" \"NV\" \"NY\" \"OH\" \"OK\" \"OR\" \"PA\" \"RI\" \"SC\" \"SD\" \"TN\"\n[46] \"TX\" \"UT\" \"VA\" \"VT\" \"WA\" \"WI\" \"WV\" \"WY\"\n\n\nLooking through the unique listings of the ‘state’ column, we find ‘DC’ hiding in there, being sneaky and upping our “state” count to 53."
  },
  {
    "objectID": "posts/TeresaLardo_Challenge1.html#visualization",
    "href": "posts/TeresaLardo_Challenge1.html#visualization",
    "title": "Challenge 1: Railroad Workers 2012",
    "section": "Visualization",
    "text": "Visualization\nWe can use a horizontal bar graph to show which areas had the most railroad employees in 2012. Because we know from the dim() function that this data set includes 2930 different counties, a bar graph of the number of state employees by county would be super long and overwhelming. So let’s instead opt to use employee counts by state instead of county. Using states will still give us a graph with 53 bars, so let’s add some color to distinguish consecutive bars from each other.\n\n\nCode\n# Access ggplot2 and set up a horizontal bar graph to display employees by state\nlibrary(ggplot2)\n\nst_emp_viz <- ggplot(railroad, aes(x=state, y=total_employees, fill=state)) + \n  geom_bar(stat = \"identity\") + \n  coord_flip() + \n  theme(legend.position = \"none\")\n\n# Add a title as well as labels for the x- and y-axes\nst_emp_viz <- st_emp_viz + ggtitle(\"Railroad Employees by State (2012)\") + xlab(\"State\") + ylab(\"Total Employees\")\nst_emp_viz\n\n\n\n\n\nThe horizontal bar graph shows that the 3 states with the highest number of railroad employees in 2012 were Texas, Illinois, and New York, which all surpassed 15000 employees. Nebraska, California, and Pennsylvania have the next highest values, with all 3 states surpassing 12500."
  },
  {
    "objectID": "posts/TeresaLardo_Challenge1.html#highest-values-by-county",
    "href": "posts/TeresaLardo_Challenge1.html#highest-values-by-county",
    "title": "Challenge 1: Railroad Workers 2012",
    "section": "Highest Values by County",
    "text": "Highest Values by County\nLet’s do a little bit of sorting to see how the data set reflects or differs from our bar graph.\n\n\nCode\n# Arrange the data set in descending order so the counties with the most employees appear at the top\nsorted_by_county <- railroad %>% \n  arrange(-total_employees)\n\nhead(sorted_by_county, 15)\n\n\n# A tibble: 15 × 3\n   state county           total_employees\n   <chr> <chr>                      <dbl>\n 1 IL    COOK                        8207\n 2 TX    TARRANT                     4235\n 3 NE    DOUGLAS                     3797\n 4 NY    SUFFOLK                     3685\n 5 VA    INDEPENDENT CITY            3249\n 6 FL    DUVAL                       3073\n 7 CA    SAN BERNARDINO              2888\n 8 CA    LOS ANGELES                 2545\n 9 TX    HARRIS                      2535\n10 NE    LINCOLN                     2289\n11 NY    NASSAU                      2076\n12 MO    JACKSON                     2055\n13 IN    LAKE                        1999\n14 IL    WILL                        1784\n15 PA    PHILADELPHIA                1649\n\n\nSince there are so many counties in this data set, I’ve expanded the head() view to the top 15 values. We can see that each of the top 6 states from our bar graph is represented in the top 15 counties. Several counties in other states also had particularly high numbers of railroad employees in 2012."
  },
  {
    "objectID": "posts/TeresaLardo_Challenge1.html#conclusion",
    "href": "posts/TeresaLardo_Challenge1.html#conclusion",
    "title": "Challenge 1: Railroad Workers 2012",
    "section": "Conclusion",
    "text": "Conclusion\nThis data set shows that at the state level, the states of Texas, Illinois, and New York had the highest total number of railroad employees in the year 2012. At the county level, the highest number of railroad employees were based in Cook County, Illinois (8207); Tarrant County, Texas (4235); and Douglas County, Nebraska (3797). Considering the data set describes data from the year 2012 specifically, the data was likely gathered via local census."
  },
  {
    "objectID": "posts/TeresaLardo_Challenge2.html",
    "href": "posts/TeresaLardo_Challenge2.html",
    "title": "Challenge 2",
    "section": "",
    "text": "For this challenge, I’ll read in the csv file on hotel bookings.\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.1     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 1.0.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCode\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)\nlibrary(readr)\nhotel_bookings <- read_csv(\"_data/hotel_bookings.csv\", show_col_types = FALSE)\n\n\n\n\n\n\nCode\nhead(hotel_bookings)\n\n\n# A tibble: 6 × 32\n  hotel   is_ca…¹ lead_…² arriv…³ arriv…⁴ arriv…⁵ arriv…⁶ stays…⁷ stays…⁸ adults\n  <chr>     <dbl>   <dbl>   <dbl> <chr>     <dbl>   <dbl>   <dbl>   <dbl>  <dbl>\n1 Resort…       0     342    2015 July         27       1       0       0      2\n2 Resort…       0     737    2015 July         27       1       0       0      2\n3 Resort…       0       7    2015 July         27       1       0       1      1\n4 Resort…       0      13    2015 July         27       1       0       1      1\n5 Resort…       0      14    2015 July         27       1       0       2      2\n6 Resort…       0      14    2015 July         27       1       0       2      2\n# … with 22 more variables: children <dbl>, babies <dbl>, meal <chr>,\n#   country <chr>, market_segment <chr>, distribution_channel <chr>,\n#   is_repeated_guest <dbl>, previous_cancellations <dbl>,\n#   previous_bookings_not_canceled <dbl>, reserved_room_type <chr>,\n#   assigned_room_type <chr>, booking_changes <dbl>, deposit_type <chr>,\n#   agent <chr>, company <chr>, days_in_waiting_list <dbl>,\n#   customer_type <chr>, adr <dbl>, required_car_parking_spaces <dbl>, …\n\n\n\n\n\n\n\nCode\ntail(hotel_bookings)\n\n\n# A tibble: 6 × 32\n  hotel   is_ca…¹ lead_…² arriv…³ arriv…⁴ arriv…⁵ arriv…⁶ stays…⁷ stays…⁸ adults\n  <chr>     <dbl>   <dbl>   <dbl> <chr>     <dbl>   <dbl>   <dbl>   <dbl>  <dbl>\n1 City H…       0      21    2017 August       35      30       2       5      2\n2 City H…       0      23    2017 August       35      30       2       5      2\n3 City H…       0     102    2017 August       35      31       2       5      3\n4 City H…       0      34    2017 August       35      31       2       5      2\n5 City H…       0     109    2017 August       35      31       2       5      2\n6 City H…       0     205    2017 August       35      29       2       7      2\n# … with 22 more variables: children <dbl>, babies <dbl>, meal <chr>,\n#   country <chr>, market_segment <chr>, distribution_channel <chr>,\n#   is_repeated_guest <dbl>, previous_cancellations <dbl>,\n#   previous_bookings_not_canceled <dbl>, reserved_room_type <chr>,\n#   assigned_room_type <chr>, booking_changes <dbl>, deposit_type <chr>,\n#   agent <chr>, company <chr>, days_in_waiting_list <dbl>,\n#   customer_type <chr>, adr <dbl>, required_car_parking_spaces <dbl>, …"
  },
  {
    "objectID": "posts/TeresaLardo_Challenge2.html#describe-the-data",
    "href": "posts/TeresaLardo_Challenge2.html#describe-the-data",
    "title": "Challenge 2",
    "section": "Describe the data",
    "text": "Describe the data\n\nDimensions\n\n\nCode\n#Find out the dimensions of the tibble\ndim(hotel_bookings)\n\n\n[1] 119390     32\n\n\n\n\nUnique Hotels\n\n\nCode\n#Find out which hotels are listed in the hotel column\nunique(hotel_bookings$hotel)\n\n\n[1] \"Resort Hotel\" \"City Hotel\"  \n\n\nThe cases in this dataset are just under 120,000 individual bookings at two hotels (Resort Hotel and City Hotel) over the time period July 2015 through August 2017. There are 32 variables in this dataset, including:\n- meal packages,\n- how far in advance the booking was created (lead time),\n- average daily rate,\n- whether a booking was canceled or not,\n- type of room reserved/assigned, and\n- how many adults, children, and babies are associated with each booking.\nBecause each variable ought to have a column, we can look at all the variables in this dataset by using the colnames() function.\n\n\nCode\ncolnames(hotel_bookings)\n\n\n [1] \"hotel\"                          \"is_canceled\"                   \n [3] \"lead_time\"                      \"arrival_date_year\"             \n [5] \"arrival_date_month\"             \"arrival_date_week_number\"      \n [7] \"arrival_date_day_of_month\"      \"stays_in_weekend_nights\"       \n [9] \"stays_in_week_nights\"           \"adults\"                        \n[11] \"children\"                       \"babies\"                        \n[13] \"meal\"                           \"country\"                       \n[15] \"market_segment\"                 \"distribution_channel\"          \n[17] \"is_repeated_guest\"              \"previous_cancellations\"        \n[19] \"previous_bookings_not_canceled\" \"reserved_room_type\"            \n[21] \"assigned_room_type\"             \"booking_changes\"               \n[23] \"deposit_type\"                   \"agent\"                         \n[25] \"company\"                        \"days_in_waiting_list\"          \n[27] \"customer_type\"                  \"adr\"                           \n[29] \"required_car_parking_spaces\"    \"total_of_special_requests\"     \n[31] \"reservation_status\"             \"reservation_status_date\"       \n\n\nThe “is_canceled” and “reservation_status” columns clue us in to the fact that the cases are bookings made but not necessarily actual stays at the hotels, as some customers canceled or no-showed. This indicates that the data was most likely gathered from the booking systems of the hotels themselves.\n\n\nCode\n# Show unique values under is_canceled column\nunique(hotel_bookings$is_canceled)\n\n\n[1] 0 1\n\n\nCode\n# Show unique values under reservation_status column\nunique(hotel_bookings$reservation_status)\n\n\n[1] \"Check-Out\" \"Canceled\"  \"No-Show\""
  },
  {
    "objectID": "posts/TeresaLardo_Challenge2.html#grouped-summary-statistics",
    "href": "posts/TeresaLardo_Challenge2.html#grouped-summary-statistics",
    "title": "Challenge 2",
    "section": "Grouped Summary Statistics",
    "text": "Grouped Summary Statistics\nBecause this dataset has so many variables, there are many potential ways to group data. We could group our data by hotel, by bookings that turned into actual hotel stays (where reservation_status is ‘Check-Out’), by bookings that include children or babies (where the children or babies column is not ‘0’), by group bookings (where market_segment is ‘groups’), by bookings with a full deposit (where deposit_type is ‘Non Refund’), by bookings for which the reserved and assign room types differ (where reserved_room_type is not the same as the value in assigned_room_type), by bookings with different types of meal packages, etc.\n\nWhen are the hotels in demand?\nLet’s look at average lead time (number of days between booking and anticipated arrival date) to get clues into when during the year each hotel is more likely to be booked far in advanced. Let’s also filter out bookings that were cancelled.\n\n\nCode\nlibrary(dplyr)\nhotel_bookings %>%\n  filter(reservation_status == \"Check-Out\") %>%\n  group_by(arrival_date_month, hotel) %>%\n  select(lead_time) %>%\n  summarize_all(mean) %>%\n  ungroup() %>%\n  arrange(desc(lead_time))\n\n\n# A tibble: 24 × 3\n   arrival_date_month hotel        lead_time\n   <chr>              <chr>            <dbl>\n 1 September          Resort Hotel     146. \n 2 July               City Hotel       133. \n 3 June               Resort Hotel     126. \n 4 May                Resort Hotel     107. \n 5 June               City Hotel       103. \n 6 October            Resort Hotel     103. \n 7 August             City Hotel       101. \n 8 July               Resort Hotel      96.2\n 9 August             Resort Hotel      92.8\n10 May                City Hotel        90.0\n# … with 14 more rows\n\n\nReservations for September at Resort Hotel have the highest average lead time, with July reservations at City Hotel following behind. The lowest average lead times for City Hotel are in January, February, and Dcember. The lowest average lead times for Resort Hotel are in November, February, and January."
  },
  {
    "objectID": "posts/TeresaLardo_Challenge2.html#central-tendency-and-dispersion",
    "href": "posts/TeresaLardo_Challenge2.html#central-tendency-and-dispersion",
    "title": "Challenge 2",
    "section": "Central Tendency and Dispersion",
    "text": "Central Tendency and Dispersion\nDespite the 32 different variables in this dataset, only 13 columns can be directly used to get means, medians, and modes. Other columns may appear to be numeric but answer Yes/No questions with 0 or 1, or list numbers referring to dates (such as week of the year or day of the month), which would not benefit from being averaged.\n\nHotel Stays\nI will filter for bookings that actually turned into hotel stays (where the reservation status is “Check-Out” as opposed to “No show” or “Canceled”).\n\n\nCode\n#Create a vector containing the indices of the columns for summary statistics\nstat_cols <- c(3, 8:12, 18, 19, 22, 26, 28:30)\n\n#Load summarytools package to us descr()\nlibrary(summarytools)\n\nhotel_stays <- hotel_bookings %>% \n  filter(reservation_status == \"Check-Out\")\n\ndescr(hotel_stays[stat_cols])\n\n\nDescriptive Statistics  \nhotel_stays  \nN: 75166  \n\n                         adr     adults     babies   booking_changes   children\n----------------- ---------- ---------- ---------- ----------------- ----------\n             Mean      99.99       1.83       0.01              0.29       0.10\n          Std.Dev      49.21       0.51       0.11              0.74       0.39\n              Min      -6.38       0.00       0.00              0.00       0.00\n               Q1      67.50       2.00       0.00              0.00       0.00\n           Median      92.50       2.00       0.00              0.00       0.00\n               Q3     125.00       2.00       0.00              0.00       0.00\n              Max     510.00       4.00      10.00             21.00       3.00\n              MAD      40.77       0.00       0.00              0.00       0.00\n              IQR      57.50       0.00       0.00              0.00       0.00\n               CV       0.49       0.28      10.89              2.51       3.82\n         Skewness       0.96      -0.39      23.40              5.40       4.05\n      SE.Skewness       0.01       0.01       0.01              0.01       0.01\n         Kurtosis       2.04       0.86    1416.23             66.61      16.20\n          N.Valid   75166.00   75166.00   75166.00          75166.00   75166.00\n        Pct.Valid     100.00     100.00     100.00            100.00     100.00\n\nTable: Table continues below\n\n \n\n                    days_in_waiting_list   lead_time   previous_bookings_not_canceled\n----------------- ---------------------- ----------- --------------------------------\n             Mean                   1.59       79.98                             0.20\n          Std.Dev                  14.78       91.11                             1.81\n              Min                   0.00        0.00                             0.00\n               Q1                   0.00        9.00                             0.00\n           Median                   0.00       45.00                             0.00\n               Q3                   0.00      124.00                             0.00\n              Max                 379.00      737.00                            72.00\n              MAD                   0.00       62.27                             0.00\n              IQR                   0.00      115.00                             0.00\n               CV                   9.30        1.14                             8.92\n         Skewness                  12.60        1.53                            19.60\n      SE.Skewness                   0.01        0.01                             0.01\n         Kurtosis                 192.72        2.29                           534.16\n          N.Valid               75166.00    75166.00                         75166.00\n        Pct.Valid                 100.00      100.00                           100.00\n\nTable: Table continues below\n\n \n\n                    previous_cancellations   required_car_parking_spaces   stays_in_week_nights\n----------------- ------------------------ ----------------------------- ----------------------\n             Mean                     0.02                          0.10                   2.46\n          Std.Dev                     0.27                          0.30                   1.92\n              Min                     0.00                          0.00                   0.00\n               Q1                     0.00                          0.00                   1.00\n           Median                     0.00                          0.00                   2.00\n               Q3                     0.00                          0.00                   3.00\n              Max                    13.00                          8.00                  50.00\n              MAD                     0.00                          0.00                   1.48\n              IQR                     0.00                          0.00                   2.00\n               CV                    17.25                          3.05                   0.78\n         Skewness                    29.14                          3.14                   2.75\n      SE.Skewness                     0.01                          0.01                   0.01\n         Kurtosis                  1043.46                         17.84                  25.61\n          N.Valid                 75166.00                      75166.00               75166.00\n        Pct.Valid                   100.00                        100.00                 100.00\n\nTable: Table continues below\n\n \n\n                    stays_in_weekend_nights   total_of_special_requests\n----------------- ------------------------- ---------------------------\n             Mean                      0.93                        0.71\n          Std.Dev                      0.99                        0.83\n              Min                      0.00                        0.00\n               Q1                      0.00                        0.00\n           Median                      1.00                        1.00\n               Q3                      2.00                        1.00\n              Max                     19.00                        5.00\n              MAD                      1.48                        1.48\n              IQR                      2.00                        1.00\n               CV                      1.07                        1.17\n         Skewness                      1.40                        1.08\n      SE.Skewness                      0.01                        0.01\n         Kurtosis                      8.36                        0.90\n          N.Valid                  75166.00                    75166.00\n        Pct.Valid                    100.00                      100.00\n\n\n\n\nCancelled Bookings\nTo contrast with the summary statistics of the bookings that turned into hotel stays, let’s filter for only cancelled bookings at the two hotels.\n\n\nCode\ncanceled_bookings <- hotel_bookings %>%\n  filter(is_canceled == 1) \n\ndescr(canceled_bookings[stat_cols])\n\n\nDescriptive Statistics  \ncanceled_bookings  \nN: 44224  \n\n                         adr     adults     babies   booking_changes   children\n----------------- ---------- ---------- ---------- ----------------- ----------\n             Mean     104.96       1.90       0.00              0.10       0.11\n          Std.Dev      52.57       0.68       0.06              0.45       0.41\n              Min       0.00       0.00       0.00              0.00       0.00\n               Q1      72.41       2.00       0.00              0.00       0.00\n           Median      96.20       2.00       0.00              0.00       0.00\n               Q3     127.62       2.00       0.00              0.00       0.00\n              Max    5400.00      55.00       2.00             16.00      10.00\n              MAD      40.22       0.00       0.00              0.00       0.00\n              IQR      55.21       0.00       0.00              0.00       0.00\n               CV       0.50       0.36      16.34              4.59       3.86\n         Skewness      23.89      31.03      16.64              7.75       4.19\n      SE.Skewness       0.01       0.01       0.01              0.01       0.01\n         Kurtosis    2327.31    1935.19     286.17            111.72      21.95\n          N.Valid   44224.00   44224.00   44224.00          44224.00   44220.00\n        Pct.Valid     100.00     100.00     100.00            100.00      99.99\n\nTable: Table continues below\n\n \n\n                    days_in_waiting_list   lead_time   previous_bookings_not_canceled\n----------------- ---------------------- ----------- --------------------------------\n             Mean                   3.56      144.85                             0.03\n          Std.Dev                  21.49      118.62                             0.68\n              Min                   0.00        0.00                             0.00\n               Q1                   0.00       48.00                             0.00\n           Median                   0.00      113.00                             0.00\n               Q3                   0.00      214.00                             0.00\n              Max                 391.00      629.00                            58.00\n              MAD                   0.00      111.19                             0.00\n              IQR                   0.00      166.00                             0.00\n               CV                   6.03        0.82                            27.03\n         Skewness                  10.64        1.03                            46.75\n      SE.Skewness                   0.01        0.01                             0.01\n         Kurtosis                 151.19        0.78                          2794.70\n          N.Valid               44224.00    44224.00                         44224.00\n        Pct.Valid                 100.00      100.00                           100.00\n\nTable: Table continues below\n\n \n\n                    previous_cancellations   required_car_parking_spaces   stays_in_week_nights\n----------------- ------------------------ ----------------------------- ----------------------\n             Mean                     0.21                          0.00                   2.56\n          Std.Dev                     1.33                          0.00                   1.88\n              Min                     0.00                          0.00                   0.00\n               Q1                     0.00                          0.00                   1.00\n           Median                     0.00                          0.00                   2.00\n               Q3                     0.00                          0.00                   3.00\n              Max                    26.00                          0.00                  40.00\n              MAD                     0.00                          0.00                   1.48\n              IQR                     0.00                          0.00                   2.00\n               CV                     6.39                           NaN                   0.73\n         Skewness                    16.12                           NaN                   3.08\n      SE.Skewness                     0.01                          0.01                   0.01\n         Kurtosis                   282.86                           NaN                  21.82\n          N.Valid                 44224.00                      44224.00               44224.00\n        Pct.Valid                   100.00                        100.00                 100.00\n\nTable: Table continues below\n\n \n\n                    stays_in_weekend_nights   total_of_special_requests\n----------------- ------------------------- ---------------------------\n             Mean                      0.93                        0.33\n          Std.Dev                      1.01                        0.65\n              Min                      0.00                        0.00\n               Q1                      0.00                        0.00\n           Median                      1.00                        0.00\n               Q3                      2.00                        0.00\n              Max                     16.00                        5.00\n              MAD                      1.48                        0.00\n              IQR                      2.00                        0.00\n               CV                      1.09                        1.97\n         Skewness                      1.35                        2.06\n      SE.Skewness                      0.01                        0.01\n         Kurtosis                      5.26                        3.93\n          N.Valid                  44224.00                    44224.00\n        Pct.Valid                    100.00                      100.00\n\n\nI notice the mean & median values for ADR is different in the summary stats for hotel stays vs. cancelled bookings. The max ADR value in cancelled bookings is 5400 - possibly a reason that reservation was cancelled.\nI also notice that the required car parking spaces variable seems to only have values of zero for the canceled bookings subset. This suggests that information about parking spaces is not collected until the check-in process when customers physically arrive to the hotels."
  },
  {
    "objectID": "posts/TeresaLardo_Challenge3.html",
    "href": "posts/TeresaLardo_Challenge3.html",
    "title": "Challenge 3: Animal Weights",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)"
  },
  {
    "objectID": "posts/TeresaLardo_Challenge3.html#read-in-data",
    "href": "posts/TeresaLardo_Challenge3.html#read-in-data",
    "title": "Challenge 3: Animal Weights",
    "section": "Read in data",
    "text": "Read in data\nFor this challenge, I’ll read in the csv file on animal weights.\n\n\nCode\nlibrary(readr)\nanimal_weight <- read_csv(\"_data/animal_weight.csv\", show_col_types =  FALSE)\nhead(animal_weight)\n\n\n# A tibble: 6 × 17\n  IPCC A…¹ Cattl…² Cattl…³ Buffa…⁴ Swine…⁵ Swine…⁶ Chick…⁷ Chick…⁸ Ducks Turkeys\n  <chr>      <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <dbl>   <dbl>\n1 Indian …     275     110     295      28      28     0.9     1.8   2.7     6.8\n2 Eastern…     550     391     380      50     180     0.9     1.8   2.7     6.8\n3 Africa       275     173     380      28      28     0.9     1.8   2.7     6.8\n4 Oceania      500     330     380      45     180     0.9     1.8   2.7     6.8\n5 Western…     600     420     380      50     198     0.9     1.8   2.7     6.8\n6 Latin A…     400     305     380      28      28     0.9     1.8   2.7     6.8\n# … with 7 more variables: Sheep <dbl>, Goats <dbl>, Horses <dbl>, Asses <dbl>,\n#   Mules <dbl>, Camels <dbl>, Llamas <dbl>, and abbreviated variable names\n#   ¹​`IPCC Area`, ²​`Cattle - dairy`, ³​`Cattle - non-dairy`, ⁴​Buffaloes,\n#   ⁵​`Swine - market`, ⁶​`Swine - breeding`, ⁷​`Chicken - Broilers`,\n#   ⁸​`Chicken - Layers`\n\n\n\nBriefly describe the data\n\n\nCode\ndim(animal_weight)\n\n\n[1]  9 17\n\n\nCode\ncolnames(animal_weight)\n\n\n [1] \"IPCC Area\"          \"Cattle - dairy\"     \"Cattle - non-dairy\"\n [4] \"Buffaloes\"          \"Swine - market\"     \"Swine - breeding\"  \n [7] \"Chicken - Broilers\" \"Chicken - Layers\"   \"Ducks\"             \n[10] \"Turkeys\"            \"Sheep\"              \"Goats\"             \n[13] \"Horses\"             \"Asses\"              \"Mules\"             \n[16] \"Camels\"             \"Llamas\"            \n\n\nCode\nunique(animal_weight$`IPCC Area`)\n\n\n[1] \"Indian Subcontinent\" \"Eastern Europe\"      \"Africa\"             \n[4] \"Oceania\"             \"Western Europe\"      \"Latin America\"      \n[7] \"Asia\"                \"Middle east\"         \"Northern America\"   \n\n\nThe data set shows the weights of 16 different animal types (for agricultural use) for 9 different geographic regions. There are 16 different types of animal (including different uses for the same animal - such as chickens meant for broiling and chickens meant for laying eggs or dairy/nondairy cattle). The data set should be flipped so that instead of one long row giving 16 different weights for one geographic region, we only see one observation (animal weight) per row."
  },
  {
    "objectID": "posts/TeresaLardo_Challenge3.html#anticipate-the-end-result",
    "href": "posts/TeresaLardo_Challenge3.html#anticipate-the-end-result",
    "title": "Challenge 3: Animal Weights",
    "section": "Anticipate the End Result",
    "text": "Anticipate the End Result\nWe’ll use pivot_longer() to list each of the 16 animal types under a column called Animals and their weights under a column called Weight instead. This should result in a much longer version of our current tibble, where each IPCC area (geographic region) will appear 16 times - once per different type of animal - instead of once. As there are 9 IPCC areas listed now, this should end up being a tibble of 144 rows (observations) and 3 columns (IPCC area, Animals, and Weight)."
  },
  {
    "objectID": "posts/TeresaLardo_Challenge3.html#pivot-the-data",
    "href": "posts/TeresaLardo_Challenge3.html#pivot-the-data",
    "title": "Challenge 3: Animal Weights",
    "section": "Pivot the Data",
    "text": "Pivot the Data\nNow we will pivot all of the columns describing animal weights (columns 2 through 17) so that the name of each of these columns (Cattle - dairy through Llamas) is contained under a new column titled Animals. The values listed under the original columns will move to another new column, titled Weight.\n\n\nCode\nanimal_weight<-pivot_longer(animal_weight, col = c(2:17),\n                 names_to=\"Animals\",\n                 values_to = \"Weight\")\nanimal_weight\n\n\n# A tibble: 144 × 3\n   `IPCC Area`         Animals            Weight\n   <chr>               <chr>               <dbl>\n 1 Indian Subcontinent Cattle - dairy      275  \n 2 Indian Subcontinent Cattle - non-dairy  110  \n 3 Indian Subcontinent Buffaloes           295  \n 4 Indian Subcontinent Swine - market       28  \n 5 Indian Subcontinent Swine - breeding     28  \n 6 Indian Subcontinent Chicken - Broilers    0.9\n 7 Indian Subcontinent Chicken - Layers      1.8\n 8 Indian Subcontinent Ducks                 2.7\n 9 Indian Subcontinent Turkeys               6.8\n10 Indian Subcontinent Sheep                28  \n# … with 134 more rows\n\n\n\nCheck Dimensions of Pivoted Data\nBefore pivoting, I calculated that the new dimensions would be 144 rows and 3 columns, where each row describes the weight of a type of agricultural animal in a geographic region.\n\n\nCode\ndim(animal_weight)\n\n\n[1] 144   3\n\n\nNow that the data has been pivoted long, our resulting tibble dimensions are \\(144x3\\) as expected."
  },
  {
    "objectID": "posts/TeresaLardo_Challenge4.html",
    "href": "posts/TeresaLardo_Challenge4.html",
    "title": "Challenge 4: Hotel Bookings",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)"
  },
  {
    "objectID": "posts/TeresaLardo_Challenge4.html#read-in-data",
    "href": "posts/TeresaLardo_Challenge4.html#read-in-data",
    "title": "Challenge 4: Hotel Bookings",
    "section": "Read in data",
    "text": "Read in data\nFor this challenge, we’ll read in the csv file on hotel bookings.\n\n\nCode\nlibrary(readr)\nhotel_bookings <- read_csv(\"_data/hotel_bookings.csv\", show_col_types = FALSE)\n\n\n\nBriefly describe the data\n\n\nCode\nhead(hotel_bookings, 10)\n\n\n# A tibble: 10 × 32\n   hotel  is_ca…¹ lead_…² arriv…³ arriv…⁴ arriv…⁵ arriv…⁶ stays…⁷ stays…⁸ adults\n   <chr>    <dbl>   <dbl>   <dbl> <chr>     <dbl>   <dbl>   <dbl>   <dbl>  <dbl>\n 1 Resor…       0     342    2015 July         27       1       0       0      2\n 2 Resor…       0     737    2015 July         27       1       0       0      2\n 3 Resor…       0       7    2015 July         27       1       0       1      1\n 4 Resor…       0      13    2015 July         27       1       0       1      1\n 5 Resor…       0      14    2015 July         27       1       0       2      2\n 6 Resor…       0      14    2015 July         27       1       0       2      2\n 7 Resor…       0       0    2015 July         27       1       0       2      2\n 8 Resor…       0       9    2015 July         27       1       0       2      2\n 9 Resor…       1      85    2015 July         27       1       0       3      2\n10 Resor…       1      75    2015 July         27       1       0       3      2\n# … with 22 more variables: children <dbl>, babies <dbl>, meal <chr>,\n#   country <chr>, market_segment <chr>, distribution_channel <chr>,\n#   is_repeated_guest <dbl>, previous_cancellations <dbl>,\n#   previous_bookings_not_canceled <dbl>, reserved_room_type <chr>,\n#   assigned_room_type <chr>, booking_changes <dbl>, deposit_type <chr>,\n#   agent <chr>, company <chr>, days_in_waiting_list <dbl>,\n#   customer_type <chr>, adr <dbl>, required_car_parking_spaces <dbl>, …\n\n\nCode\ntail(hotel_bookings, 10)\n\n\n# A tibble: 10 × 32\n   hotel  is_ca…¹ lead_…² arriv…³ arriv…⁴ arriv…⁵ arriv…⁶ stays…⁷ stays…⁸ adults\n   <chr>    <dbl>   <dbl>   <dbl> <chr>     <dbl>   <dbl>   <dbl>   <dbl>  <dbl>\n 1 City …       0      44    2017 August       35      31       1       3      2\n 2 City …       0     188    2017 August       35      31       2       3      2\n 3 City …       0     135    2017 August       35      30       2       4      3\n 4 City …       0     164    2017 August       35      31       2       4      2\n 5 City …       0      21    2017 August       35      30       2       5      2\n 6 City …       0      23    2017 August       35      30       2       5      2\n 7 City …       0     102    2017 August       35      31       2       5      3\n 8 City …       0      34    2017 August       35      31       2       5      2\n 9 City …       0     109    2017 August       35      31       2       5      2\n10 City …       0     205    2017 August       35      29       2       7      2\n# … with 22 more variables: children <dbl>, babies <dbl>, meal <chr>,\n#   country <chr>, market_segment <chr>, distribution_channel <chr>,\n#   is_repeated_guest <dbl>, previous_cancellations <dbl>,\n#   previous_bookings_not_canceled <dbl>, reserved_room_type <chr>,\n#   assigned_room_type <chr>, booking_changes <dbl>, deposit_type <chr>,\n#   agent <chr>, company <chr>, days_in_waiting_list <dbl>,\n#   customer_type <chr>, adr <dbl>, required_car_parking_spaces <dbl>, …\n\n\n\n\nCode\ndim(hotel_bookings)\n\n\n[1] 119390     32\n\n\nThe data set describes just under 120,000 bookings at two hotels over the course of 2 years - July 2015 through August 2017. There are 32 variables."
  },
  {
    "objectID": "posts/TeresaLardo_Challenge4.html#identify-variables-that-need-to-be-mutated",
    "href": "posts/TeresaLardo_Challenge4.html#identify-variables-that-need-to-be-mutated",
    "title": "Challenge 4: Hotel Bookings",
    "section": "Identify variables that need to be mutated",
    "text": "Identify variables that need to be mutated\nThis data set has many variables, and some of them can be combined. For instance, the arrival date for each booking is broken into 4 different variables - year of arrival, month of arrival, day of the month of arrival, and week of the year of arrival. These could be used to break down the data and create visualizations showing which months or even weeks of the year are the most/least booked, but that’s still a lot of variables just to answer the question “when does the customer plan to show up?”\n\nCreate a single Arrival Date column\nWe can use the mutate() and make_date() functions to turn some of these columns into a single column that lists the entire date in a date format. Because the column showing the expected month of arrival uses the names of the months - July, August, etc. - instead of the number of the month (1-12), the values in that column will also have to be altered so we can use the make_date() function.\n\n\nCode\n# Load dplyr and lubridate from the library to enable the piping operator and the make_date function\nlibrary(dplyr)\nlibrary(lubridate)\nhotel_bookings <- hotel_bookings %>%\n# Use mutate and case_when to change the month values from names to numbers  \n    mutate(month = case_when(\n       arrival_date_month == \"January\" ~ 1,\n       arrival_date_month == \"February\" ~ 2,\n       arrival_date_month == \"March\" ~ 3,\n       arrival_date_month == \"April\" ~ 4,\n       arrival_date_month == \"May\" ~ 5,\n       arrival_date_month == \"June\" ~ 6,\n       arrival_date_month == \"July\" ~ 7,\n       arrival_date_month == \"August\" ~ 8,\n       arrival_date_month == \"September\" ~ 9,\n       arrival_date_month == \"October\" ~ 10,\n       arrival_date_month == \"November\" ~ 11,\n       arrival_date_month == \"December\" ~ 12,\n     )) %>%\n# Use the year, day, and new month columns to create a new column showing the entire arrival date\n    mutate(arrival_date = make_date(arrival_date_year, month, arrival_date_day_of_month)) %>%\n# Use select to remove the extraneous date columns\n    select(-c(arrival_date_year, arrival_date_month, arrival_date_day_of_month, month, arrival_date_week_number)) %>%\n# Use select to move the new arrival_date column closer to the left side of the data set\n    select(hotel, arrival_date, everything())\n\n\nBecause we’ve removed 4 of the original date columns (year, month, day, and week) and added one new column to show the entire date of expected arrival, the number of columns (variables) in our data set should change from 32 to 29.\n\n\nCode\ndim(hotel_bookings)\n\n\n[1] 119390     29\n\n\nUsing the dim() function confirms our new number of variables.\n\n\nCode\nhead(hotel_bookings)\n\n\n# A tibble: 6 × 29\n  hotel   arrival_…¹ is_ca…² lead_…³ stays…⁴ stays…⁵ adults child…⁶ babies meal \n  <chr>   <date>       <dbl>   <dbl>   <dbl>   <dbl>  <dbl>   <dbl>  <dbl> <chr>\n1 Resort… 2015-07-01       0     342       0       0      2       0      0 BB   \n2 Resort… 2015-07-01       0     737       0       0      2       0      0 BB   \n3 Resort… 2015-07-01       0       7       0       1      1       0      0 BB   \n4 Resort… 2015-07-01       0      13       0       1      1       0      0 BB   \n5 Resort… 2015-07-01       0      14       0       2      2       0      0 BB   \n6 Resort… 2015-07-01       0      14       0       2      2       0      0 BB   \n# … with 19 more variables: country <chr>, market_segment <chr>,\n#   distribution_channel <chr>, is_repeated_guest <dbl>,\n#   previous_cancellations <dbl>, previous_bookings_not_canceled <dbl>,\n#   reserved_room_type <chr>, assigned_room_type <chr>, booking_changes <dbl>,\n#   deposit_type <chr>, agent <chr>, company <chr>, days_in_waiting_list <dbl>,\n#   customer_type <chr>, adr <dbl>, required_car_parking_spaces <dbl>,\n#   total_of_special_requests <dbl>, reservation_status <chr>, …\n\n\n\n\nCombine Week & Weekend Night columns into a single Total Nights column\nOne other thing we can do to make our data more concise is to combine the columns that show the number of weekend nights and week nights. We can mutate those two columns into one that shows simply the total number of nights of the booked stay. If we add a new Total Nights column and remove the two original columns, we should have 28 columns.\n\n\nCode\nhotel_bookings <- hotel_bookings %>%\n# Mutate new column that adds the values from the weekend/week night columns\n  mutate(total_nights = stays_in_weekend_nights + stays_in_week_nights) %>%\n# Remove the original columns\n  select(-c(stays_in_weekend_nights, stays_in_week_nights)) %>%\n# Rearrange the order of the columns\n  select(hotel, arrival_date, is_canceled, lead_time, total_nights, everything())\n\n\nLet’s use the dim() function for a quick sanity check.\n\n\nCode\ndim(hotel_bookings)\n\n\n[1] 119390     28\n\n\n28 columns confirmed!\n\n\nCode\nhead(hotel_bookings)\n\n\n# A tibble: 6 × 28\n  hotel   arrival_…¹ is_ca…² lead_…³ total…⁴ adults child…⁵ babies meal  country\n  <chr>   <date>       <dbl>   <dbl>   <dbl>  <dbl>   <dbl>  <dbl> <chr> <chr>  \n1 Resort… 2015-07-01       0     342       0      2       0      0 BB    PRT    \n2 Resort… 2015-07-01       0     737       0      2       0      0 BB    PRT    \n3 Resort… 2015-07-01       0       7       1      1       0      0 BB    GBR    \n4 Resort… 2015-07-01       0      13       1      1       0      0 BB    GBR    \n5 Resort… 2015-07-01       0      14       2      2       0      0 BB    GBR    \n6 Resort… 2015-07-01       0      14       2      2       0      0 BB    GBR    \n# … with 18 more variables: market_segment <chr>, distribution_channel <chr>,\n#   is_repeated_guest <dbl>, previous_cancellations <dbl>,\n#   previous_bookings_not_canceled <dbl>, reserved_room_type <chr>,\n#   assigned_room_type <chr>, booking_changes <dbl>, deposit_type <chr>,\n#   agent <chr>, company <chr>, days_in_waiting_list <dbl>,\n#   customer_type <chr>, adr <dbl>, required_car_parking_spaces <dbl>,\n#   total_of_special_requests <dbl>, reservation_status <chr>, …"
  },
  {
    "objectID": "posts/TeresaLardo_Challenge5.html",
    "href": "posts/TeresaLardo_Challenge5.html",
    "title": "Challenge 5: Public School Characteristics",
    "section": "",
    "text": "library(tidyverse)\nlibrary(ggplot2)\nlibrary(readr)\nlibrary(dplyr)\n\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)"
  },
  {
    "objectID": "posts/TeresaLardo_Challenge5.html#read-in-data",
    "href": "posts/TeresaLardo_Challenge5.html#read-in-data",
    "title": "Challenge 5: Public School Characteristics",
    "section": "Read in data",
    "text": "Read in data\nFor this challenge, I will read in the data set on Public School characteristics.\n\npublic_schools <- read_csv(\"_data/Public_School_Characteristics_2017-18.csv\", show_col_types = FALSE)\n\n\nBriefly describe the data\nThe data set describes characteristics of just under 101,000 public schools in the United States. The variables include location information (latitude, longitude, state, school district, street address, zip code, etc.), contact information, whether or not the school is virtual, number of students per grade level, racial and ethnic background data for students, student/teacher ratio, and more.\n\nhead(public_schools)\n\n# A tibble: 6 × 79\n      X     Y OBJECTID NCESSCH     NMCNTY SURVYEAR STABR LEAID ST_LEAID LEA_NAME\n  <dbl> <dbl>    <dbl> <chr>       <chr>  <chr>    <chr> <chr> <chr>    <chr>   \n1 -149.  61.6        1 0200510004… Matan… 2017-20… AK    0200… AK-33    Matanus…\n2 -157.  71.3        2 0200610004… North… 2017-20… AK    0200… AK-36    North S…\n3 -151.  60.5        3 0200390004… Kenai… 2017-20… AK    0200… AK-24    Kenai P…\n4 -151.  60.6        4 0200390004… Kenai… 2017-20… AK    0200… AK-24    Kenai P…\n5 -151.  60.6        5 0200390005… Kenai… 2017-20… AK    0200… AK-24    Kenai P…\n6 -133.  56.1        6 0200700005… Princ… 2017-20… AK    0200… AK-44    Southea…\n# ℹ 69 more variables: SCH_NAME <chr>, LSTREET1 <chr>, LSTREET2 <chr>,\n#   LSTREET3 <lgl>, LCITY <chr>, LSTATE <chr>, LZIP <chr>, LZIP4 <chr>,\n#   PHONE <chr>, GSLO <chr>, GSHI <chr>, VIRTUAL <chr>, TOTFRL <dbl>,\n#   FRELCH <dbl>, REDLCH <dbl>, PK <dbl>, KG <dbl>, G01 <dbl>, G02 <dbl>,\n#   G03 <dbl>, G04 <dbl>, G05 <dbl>, G06 <dbl>, G07 <dbl>, G08 <dbl>,\n#   G09 <dbl>, G10 <dbl>, G11 <dbl>, G12 <dbl>, G13 <lgl>, TOTAL <dbl>,\n#   MEMBER <dbl>, AM <dbl>, HI <dbl>, BL <dbl>, WH <dbl>, HP <dbl>, TR <dbl>, …\n\n\n\ndim(public_schools)\n\n[1] 100729     79"
  },
  {
    "objectID": "posts/TeresaLardo_Challenge5.html#tidy-data",
    "href": "posts/TeresaLardo_Challenge5.html#tidy-data",
    "title": "Challenge 5: Public School Characteristics",
    "section": "Tidy Data",
    "text": "Tidy Data\n\nProblems() and Changing Data Types\nWhen I originally read the csv file in, I got a warning message that said to call problems() for more information.\n\nproblems(public_schools)\n\n# A tibble: 110 × 5\n     row   col expected           actual   file                                 \n   <int> <int> <chr>              <chr>    <chr>                                \n 1 15701    73 1/0/T/F/TRUE/FALSE 184      C:/Users/Peregrine/Documents/601_Spr…\n 2 15823    73 1/0/T/F/TRUE/FALSE 224      C:/Users/Peregrine/Documents/601_Spr…\n 3 21611    14 1/0/T/F/TRUE/FALSE Room 121 C:/Users/Peregrine/Documents/601_Spr…\n 4 44514    40 1/0/T/F/TRUE/FALSE 48       C:/Users/Peregrine/Documents/601_Spr…\n 5 44518    40 1/0/T/F/TRUE/FALSE 59       C:/Users/Peregrine/Documents/601_Spr…\n 6 44522    40 1/0/T/F/TRUE/FALSE 24       C:/Users/Peregrine/Documents/601_Spr…\n 7 44524    40 1/0/T/F/TRUE/FALSE 30       C:/Users/Peregrine/Documents/601_Spr…\n 8 44530    40 1/0/T/F/TRUE/FALSE 21       C:/Users/Peregrine/Documents/601_Spr…\n 9 44536    40 1/0/T/F/TRUE/FALSE 22       C:/Users/Peregrine/Documents/601_Spr…\n10 44537    40 1/0/T/F/TRUE/FALSE 29       C:/Users/Peregrine/Documents/601_Spr…\n# ℹ 100 more rows\n\n\nI used print(problems(public_schools), n = nrow(problems(public_schools))) and got a list of 110 issues, which all occurred in columns 14, 40, and 73. Boolean values were expected for these columns, while the actual values were often numbers or character strings. The data type of these three columns will need to be changed.\n\n# Change Column 14 (LSTREET3) from logical to character type\npublic_schools$LSTREET3 <- as.character(as.logical(public_schools$LSTREET3))\n\n# Change Column 40 (G13) from logical to numeric type\npublic_schools$G13 <- as.numeric(as.logical(public_schools$G13))\n\n# Change Column 73 (AE) from logical to numeric type\npublic_schools$AE <- as.numeric(as.logical(public_schools$AE))\n\nLet’s check the data types for these columns to make sure our changes went through as intended. We’re expecting LSTREET3 column to have a character type and the other two columns to have numeric types.\n\nclass(public_schools$LSTREET3)\n\n[1] \"character\"\n\nclass(public_schools$G13)\n\n[1] \"numeric\"\n\nclass(public_schools$AE)\n\n[1] \"numeric\"\n\n\nHurray!\n\n\nRemoving Repetitive Data\nThis data set includes a column for the survey year, which suggests that this data was taken from a longer set that includes data from different survey years. However, this set is only from one survey year, as we can see from running the unique() function for that column:\n\nunique(public_schools$SURVYEAR)\n\n[1] \"2017-2018\"\n\n\nAs this “variable” does not vary at all in our data, we can remove this from the data set.\n\n# Remove Survey Year column\npublic_schools <- public_schools %>%\n  select(-SURVYEAR)\n\nThe data set also contains two sets of columns containing the latitude and longitudinal coordinates for the schools - columns X and Y as well as columns LATCOD and LONCOD. We can remove one set of these repetitive columns without losing any unique information.\n\n# Remove columns X and Y\npublic_schools <- public_schools %>%\n  select(-c(X, Y))\n\nLet’s get a quick view of our data set to make sure these 3 columns have been removed:\n\nhead(public_schools)\n\n# A tibble: 6 × 76\n  OBJECTID NCESSCH      NMCNTY   STABR LEAID ST_LEAID LEA_NAME SCH_NAME LSTREET1\n     <dbl> <chr>        <chr>    <chr> <chr> <chr>    <chr>    <chr>    <chr>   \n1        1 020051000480 Matanus… AK    0200… AK-33    Matanus… John Sh… 3750 E …\n2        2 020061000470 North S… AK    0200… AK-36    North S… Kiita L… 5246 Ka…\n3        3 020039000448 Kenai P… AK    0200… AK-24    Kenai P… Soldotn… 158 E P…\n4        4 020039000463 Kenai P… AK    0200… AK-24    Kenai P… Kaleido… 549 N F…\n5        5 020039000513 Kenai P… AK    0200… AK-24    Kenai P… Maratho… 405 Mar…\n6        6 020070000526 Prince … AK    0200… AK-44    Southea… Whale P… 126 Bay…\n# ℹ 67 more variables: LSTREET2 <chr>, LSTREET3 <chr>, LCITY <chr>,\n#   LSTATE <chr>, LZIP <chr>, LZIP4 <chr>, PHONE <chr>, GSLO <chr>, GSHI <chr>,\n#   VIRTUAL <chr>, TOTFRL <dbl>, FRELCH <dbl>, REDLCH <dbl>, PK <dbl>,\n#   KG <dbl>, G01 <dbl>, G02 <dbl>, G03 <dbl>, G04 <dbl>, G05 <dbl>, G06 <dbl>,\n#   G07 <dbl>, G08 <dbl>, G09 <dbl>, G10 <dbl>, G11 <dbl>, G12 <dbl>,\n#   G13 <dbl>, TOTAL <dbl>, MEMBER <dbl>, AM <dbl>, HI <dbl>, BL <dbl>,\n#   WH <dbl>, HP <dbl>, TR <dbl>, FTE <dbl>, LATCOD <dbl>, LONCOD <dbl>, …"
  },
  {
    "objectID": "posts/TeresaLardo_Challenge5.html#mutation",
    "href": "posts/TeresaLardo_Challenge5.html#mutation",
    "title": "Challenge 5: Public School Characteristics",
    "section": "Mutation",
    "text": "Mutation\nThe ULOCALE variable in this data set lists 12 different settings, including “Rural: Fringe,” “Town: Remote,” “City: Mid-size,” and “Suburb: Large.” I’d like to use mutate() to create a column that categorizes each school into a smaller number of possible environments - simply Rural, Town, City, and Suburb.\n\npublic_schools <- public_schools %>%\n   mutate(ENVIRONMENT = case_when(ULOCALE %in% c(\"11-City: Large\", \"12-City: Mid-size\", \"13-City: Small\") ~ \"City\",\n                                  ULOCALE %in% c(\"21-Suburb: Large\", \"22-Suburb: Mid-size\", \"23-Suburb: Small\") ~ \"Suburb\",\n                                  ULOCALE %in% c(\"31-Town: Fringe\", \"32-Town: Distant\", \"33-Town: Remote\") ~ \"Town\",\n                                  ULOCALE %in% c(\"41-Rural: Fringe\", \"42-Rural: Distant\", \"43-Rural: Remote\") ~ \"Rural\"))"
  },
  {
    "objectID": "posts/TeresaLardo_Challenge5.html#univariate-visualizations",
    "href": "posts/TeresaLardo_Challenge5.html#univariate-visualizations",
    "title": "Challenge 5: Public School Characteristics",
    "section": "Univariate Visualizations",
    "text": "Univariate Visualizations\n\nSchool Levels\nI’d like to get a look at which levels of school (elementary, middle, etc.) are most represented in the data set. I want to try out a treemap for this to get a quick, visual sense of the proportion of each type of school level within the data set.\n\n# Create a data source to store the counts by School Level\nlevels <- public_schools %>%\n  count(SCHOOL_LEVEL)\n# Load treemapify from library\nlibrary(treemapify)\n# Create a treemap\nggplot(levels, \n       aes(fill = SCHOOL_LEVEL, \n           area = n, \n           label = SCHOOL_LEVEL)) +\n  geom_treemap() + \n  geom_treemap_text(colour = \"black\", \n                    place = \"centre\") +\n  labs(title = \"Public Schools by Level\") +\n  theme(legend.position = \"none\")\n\n\n\n\nThis tree map shows that most of the schools in this data set are elementary schools - it looks like more than half of the schools are elementary level. We can also look into more exact percentages for these school levels by using a bar chart:\n\nlibrary(scales)\n# Create data source for School Level counts and percentages\nlevel_perc <- public_schools %>%\n  count(SCHOOL_LEVEL) %>%\n  mutate(pct = n / sum(n),\n         pctlabel = paste0(round(pct*100), \"%\"))\n\n# Create a bar chart showing the percentages of each level of school\nggplot(level_perc, \n       aes(x = reorder(SCHOOL_LEVEL, -pct),\n           y = pct)) + \n  geom_bar(stat = \"identity\", \n           fill = \"steelblue\", \n           color = \"black\") +\n  geom_text(aes(label = pctlabel), \n            vjust = -0.25) +\n  scale_y_continuous(labels = percent) +\n  labs(x = \"School Levels\", \n       y = \"Percent\", \n       title  = \"School Levels for Public Schools, 2017-18\") +\n  theme(axis.text.x = element_text(angle = 45,\n                                   hjust = 1))\n\n\n\n\nThis bar chart confirms that the percentage of elementary schools within our data set is slightly over half. Compared to the tree map, the bar chart also has much more readable labels for the less represented school levels.\n\n\nOperational Status\nThe data set includes a column displaying the operational status of each school. Let’s use a bar chart to get a sense of how many schools of each status are in our data set. I’ll use coord_flip() to make this a horizontal bar chart for the sake of reading each operational status label more easily.\n\nggplot(public_schools, aes(x = SY_STATUS_TEXT)) + \n  geom_bar(fill = \"hotpink\",\n           color = \"black\") +\n  labs(title=\"Status of Public Schools, 2017-18\",\n       x = \"Operational Status\") + \n  coord_flip()\n\n\n\n\nOur horizontal bar chart shows that by far most of the schools in our data set were currently operational when the data was collected."
  },
  {
    "objectID": "posts/TeresaLardo_Challenge5.html#bivariate-visualizations",
    "href": "posts/TeresaLardo_Challenge5.html#bivariate-visualizations",
    "title": "Challenge 5: Public School Characteristics",
    "section": "Bivariate Visualizations",
    "text": "Bivariate Visualizations\n\nTotal Students in Towns, Cities, Suburbs, & Rural Areas\nLet’s create a visualization to show the total number of public school students by school environment (city, rural, suburb, and town).\n\nggplot(public_schools, aes(x=ENVIRONMENT, y=TOTAL)) +\n    geom_bar(stat = \"identity\", color=\"darkgreen\", width=0.45) + \n    xlab(\"Environment of Public Schools\") + ylab(\"Total Number of Students\") + \n    ggtitle(\"Total Public School Students by Environment Type\")\n\n\n\n\nThis visualization shows that the environment with the most public school students overall is the suburbs, with the city pulling in second. Town has the lowest number of total public school students, which makes me curious how “town” is defined for this data set.\n\n\nStudent-Teacher Ratios in Virtual/Non-Virtual Schools\nAs this data set has a variable on virtual versus non-virtual status of the schools, I’m curious to look into some of the data on virtual public schools. However, when I filtered the data set down to only virtual schools, the result was a relatively small portion of our total data. So I want to compare the virtual and non-virtual schools in terms of student-teacher ratios to see if there is any noticeable difference to be seen (beyond there being much fewer numbers of virtual schools overall).\nI will use a scatterplot in the interest of seeing where most data points gather and where more outlying points appear.\n\n# Filter out the N/A & Missing values from the VIRTUAL variable\npublic_schools <- public_schools %>%\n  filter(VIRTUAL == c(\"A virtual school\", \"Not a virtual school\"))\n\n# Student Teacher Ratios at Virtual & Non-Virtual Schools\nggplot(public_schools, \n      aes(y = factor(VIRTUAL,\n                     labels = c(\"Virtual School\", \"Non-virtual School\")),\n          x = STUTERATIO,\n          color = VIRTUAL)) +\n   geom_jitter(alpha = 0.7,\n               size = 1.5) + \n   scale_x_continuous() +\n   labs(title = \"Student-Teacher Ratios for Virtual & Non-Virtual Public Schools\",\n        x = \"Number of Students Per Teacher\",\n        y = \"Types of Schools\") +\n   theme_minimal() +\n   theme(legend.position = \"none\")\n\n\n\n\nThis scatterplot shows that the student-teacher ratios for both virtual and non-virtual public schools fall below 125 students per teacher. The plot captures an outlying data point for one of the non-virtual schools where the student-teacher ratio is nearing 25000 students to a teacher. That seems likely to be an error in the data.\nI’m interested in seeing a close-up view of the most common student-teacher ratios, so I’m going to filter out the higher student-teacher ratios and concentrate on the data points that fall below 100.\n\n# Filter out higher STR from our data set to use in a new version of the plot above\npublic_schools <- public_schools %>%\n  filter(STUTERATIO < 100)\n\n# Student Teacher Ratios at Virtual & Non-Virtual Schools\nggplot(public_schools, \n      aes(y = factor(VIRTUAL,\n                     labels = c(\"Virtual School\", \"Non-virtual School\")),\n          x = STUTERATIO,\n          color = VIRTUAL)) +\n   geom_jitter(alpha = 0.7,\n               size = 1.5) + \n   scale_x_continuous() +\n   labs(title = \"Student-Teacher Ratios under 125:1\",\n        x = \"Number of Students Per Teacher\",\n        y = \"Types of Schools\") +\n   theme_minimal() +\n   theme(legend.position = \"none\")\n\n\n\n\nThis “zoomed-in” version of the scatterplot shows us that the highest concentration of student-teacher ratios falls between 1 and roughly 30 students per teacher."
  },
  {
    "objectID": "posts/TeresaLardo_Challenge6.html",
    "href": "posts/TeresaLardo_Challenge6.html",
    "title": "Challenge 6: ADR Visualizations for Hotels",
    "section": "",
    "text": "library(tidyverse)\nlibrary(ggplot2)\nlibrary(readr)\nlibrary(dplyr)\n\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)"
  },
  {
    "objectID": "posts/TeresaLardo_Challenge6.html#read-in-data",
    "href": "posts/TeresaLardo_Challenge6.html#read-in-data",
    "title": "Challenge 6: ADR Visualizations for Hotels",
    "section": "Read in data",
    "text": "Read in data\nI’ll read in the CSV for hotel bookings.\n\nhotel_bookings <- read_csv(\"_data/hotel_bookings.csv\", show_col_types = FALSE)\n\n\nBriefly describe the data\nThis data set describes nearly 120,000 bookings (both canceled and fulfilled) at two hotels over the course of July 2015 to August 2017.\n\ndim(hotel_bookings)\n\n[1] 119390     32"
  },
  {
    "objectID": "posts/TeresaLardo_Challenge6.html#tidy-data-as-needed",
    "href": "posts/TeresaLardo_Challenge6.html#tidy-data-as-needed",
    "title": "Challenge 6: ADR Visualizations for Hotels",
    "section": "Tidy Data (as needed)",
    "text": "Tidy Data (as needed)\nI want to work with the Average Daily Rate (adr) variable, and there are some observations with values of 0 or less. In order to avoid these freebies skewing calculations, I want filter() out these rows. I also want to focus on cases where the bookings were fulfilled (i.e., not canceled), so I will also filter to control for these.\n\nhotel_bookings <- hotel_bookings %>%\n  filter(adr > 0) %>%\n  filter(is_canceled == 0)\n\n\nMutations\nIn order to create a time dependent visualization, I want to mutate() the columns describing the arrival date into a single, cohesive date column.\n\nlibrary(lubridate)\nhotel_bookings <- hotel_bookings %>%\n# Use mutate and case_when to change the month values from names to numbers  \n    mutate(month = case_when(\n       arrival_date_month == \"January\" ~ 1,\n       arrival_date_month == \"February\" ~ 2,\n       arrival_date_month == \"March\" ~ 3,\n       arrival_date_month == \"April\" ~ 4,\n       arrival_date_month == \"May\" ~ 5,\n       arrival_date_month == \"June\" ~ 6,\n       arrival_date_month == \"July\" ~ 7,\n       arrival_date_month == \"August\" ~ 8,\n       arrival_date_month == \"September\" ~ 9,\n       arrival_date_month == \"October\" ~ 10,\n       arrival_date_month == \"November\" ~ 11,\n       arrival_date_month == \"December\" ~ 12,\n     )) %>%\n# Use the year, day, and new month columns to create a new column showing the entire arrival date\n    mutate(arrival_date = make_date(arrival_date_year, month, arrival_date_day_of_month)) %>%\n# Use select to remove the extraneous date columns\n    select(-c(arrival_date_year, arrival_date_month, arrival_date_day_of_month, month, arrival_date_week_number)) %>%\n# Use select to move the new arrival_date column closer to the left side of the data set\n    select(hotel, is_canceled, lead_time, arrival_date, everything())"
  },
  {
    "objectID": "posts/TeresaLardo_Challenge6.html#time-dependent-visualization",
    "href": "posts/TeresaLardo_Challenge6.html#time-dependent-visualization",
    "title": "Challenge 6: ADR Visualizations for Hotels",
    "section": "Time Dependent Visualization",
    "text": "Time Dependent Visualization\nI want to see how the average daily rate (ADR) shifts over time at each hotel. I will create 2 different visualizations - one for each hotel - so that we can get a quick visual representation of when each hotel was more or less expensive over the course of the 2 years of data that we have.\n\ncity_bookings <- hotel_bookings %>%\n  filter(hotel == \"City Hotel\")\n\np <- ggplot(city_bookings, aes(x=arrival_date, y=adr)) +\n  geom_line(color=\"navy\") + \n  scale_x_date(date_labels = \"%b %Y\") +\n  ylab(\"Average Daily Rate ($)\") +\n  xlab(\"Arrival Date\") +\n  ggtitle(\"ADR at City Hotel\")\n\np\n\n\n\n\nThis graph shows the ADR at City Hotel from July 2015 to August 2017. From looking at this graph, we can see that the average daily rate for rooms at City Hotel increased over the course of two years, but the ADR is relatively low during late autumn. January 2017 shows a spike in the average daily rate, so there may have been some in-demand event happening during that time.\nNext, I’ll generate the ADR graph for the Resort Hotel to compare.\n\nresort_bookings <- hotel_bookings %>%\n  filter(hotel == \"Resort Hotel\")\n\nh <- ggplot(resort_bookings, aes(x=arrival_date, y=adr)) +\n  geom_line(color=\"darkgreen\") + \n  scale_x_date(date_labels = \"%b %Y\") +\n  ylab(\"Average Daily Rate ($)\") +\n  xlab(\"Arrival Date\") +\n  ggtitle(\"ADR at Resort Hotel\")\nh\n\n\n\n\nThis graph for the ADR at Resort Hotel shows that the ADR for this hotel changes more reliably on a seasonal basis. The ADR is reliably the highest of the year around August, and then decreases until January, when it gradually rises again until it hits the ADR high in August again."
  },
  {
    "objectID": "posts/TeresaLardo_Challenge6.html#visualizing-part-whole-relationships",
    "href": "posts/TeresaLardo_Challenge6.html#visualizing-part-whole-relationships",
    "title": "Challenge 6: ADR Visualizations for Hotels",
    "section": "Visualizing Part-Whole Relationships",
    "text": "Visualizing Part-Whole Relationships\nI want to see how the average daily rate (ADR) compares between different room types at the two hotels. For this, I’ll use a bar chart where the two hotels are represented by different colors.\n\nroom_bookings <- hotel_bookings %>%\n  select(hotel, assigned_room_type, adr) %>%\n  group_by(assigned_room_type) %>%\n  mutate(mean_adr = mean(adr)) %>%\n  ungroup()\n  \n\nroom_adr_viz <- ggplot(room_bookings, aes(fill=hotel, y=mean_adr, x=assigned_room_type)) +\n  geom_bar(position = \"dodge\", stat=\"identity\") +\n  labs(x = \"Assigned Room Types\", y = \"Average Daily Rate ($)\", title = \"Ave Daily Rates by Room Type\")\n\n\nroom_adr_viz\n\n\n\n\nThis graph shows that the most expensive room types are types G, H (only available at Resort Hotel), and F. City Hotel does not offer room types H or I, and Resort Hotel does not offer room type K. The cheapest room types offered by both hotels are types A, B, and D.\nWhile I could not find what each room type specifically means, the similarity of the costs for room types A, B, and D suggests to me that those room types are similar - perhaps these rooms are the most pared-down or basic with smaller capacity (i.e., 1-2 guests per room).\nThe most expensive room type - G - may be suite-style with multiple rooms, perhaps a kitchenette, with unique amenities and/or a greater capacity for guests (i.e., more suitable for larger families or groups).\nThe room types that are unique to only one of the two hotels may reflect amenities that only exist at one hotel. For example, the visualization shows that Room Type H only exists at Resort Hotel and it’s very close to the level of expense for Room Type G. Room Type H might be a large-capacity room or suite with a water view, or a detached guesthouse near a pool."
  },
  {
    "objectID": "posts/TeresaLardo_Challenge7.html",
    "href": "posts/TeresaLardo_Challenge7.html",
    "title": "Challenge 7: AirBnB Visualizations",
    "section": "",
    "text": "library(tidyverse)\nlibrary(ggplot2)\nlibrary(readr)\nlibrary(dplyr)\n\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)"
  },
  {
    "objectID": "posts/TeresaLardo_Challenge7.html#read-in-data",
    "href": "posts/TeresaLardo_Challenge7.html#read-in-data",
    "title": "Challenge 7: AirBnB Visualizations",
    "section": "Read in data",
    "text": "Read in data\nLet’s read in the .csv for the AirBnB dataset for this challenge.\n\nAB_NYC_2019 <- read_csv(\"_data/AB_NYC_2019.csv\", show_col_types = FALSE)\n\n\nBriefly describe the data\n\ndim(AB_NYC_2019)\n\n[1] 48895    16\n\n\n\nhead(AB_NYC_2019)\n\n# A tibble: 6 × 16\n     id name        host_id host_name neighbourhood_group neighbourhood latitude\n  <dbl> <chr>         <dbl> <chr>     <chr>               <chr>            <dbl>\n1  2539 Clean & qu…    2787 John      Brooklyn            Kensington        40.6\n2  2595 Skylit Mid…    2845 Jennifer  Manhattan           Midtown           40.8\n3  3647 THE VILLAG…    4632 Elisabeth Manhattan           Harlem            40.8\n4  3831 Cozy Entir…    4869 LisaRoxa… Brooklyn            Clinton Hill      40.7\n5  5022 Entire Apt…    7192 Laura     Manhattan           East Harlem       40.8\n6  5099 Large Cozy…    7322 Chris     Manhattan           Murray Hill       40.7\n# ℹ 9 more variables: longitude <dbl>, room_type <chr>, price <dbl>,\n#   minimum_nights <dbl>, number_of_reviews <dbl>, last_review <date>,\n#   reviews_per_month <dbl>, calculated_host_listings_count <dbl>,\n#   availability_365 <dbl>\n\n\n\ncolnames(AB_NYC_2019)\n\n [1] \"id\"                             \"name\"                          \n [3] \"host_id\"                        \"host_name\"                     \n [5] \"neighbourhood_group\"            \"neighbourhood\"                 \n [7] \"latitude\"                       \"longitude\"                     \n [9] \"room_type\"                      \"price\"                         \n[11] \"minimum_nights\"                 \"number_of_reviews\"             \n[13] \"last_review\"                    \"reviews_per_month\"             \n[15] \"calculated_host_listings_count\" \"availability_365\"              \n\nunique(AB_NYC_2019$neighbourhood_group)\n\n[1] \"Brooklyn\"      \"Manhattan\"     \"Queens\"        \"Staten Island\"\n[5] \"Bronx\"        \n\nunique(AB_NYC_2019$room_type)\n\n[1] \"Private room\"    \"Entire home/apt\" \"Shared room\"    \n\n\nThis data set describes almost 49,000 AirBNB listings in the New York City area during the year 2019. Each listing includes the following information:\n\nName & ID of the listing,\nHost name & ID, as well as number of listings associated with that host,\nLocation information: neighborhood group (borough), specific neighborhood, latitude, longitude,\nType of room (i.e., private room, shared room, entire home),\nMinimum length of stay in nights, price, and availability year-round, and\nNumber of reviews, reviews per month, and most recent review for that listing."
  },
  {
    "objectID": "posts/TeresaLardo_Challenge7.html#exploratory-visualizations",
    "href": "posts/TeresaLardo_Challenge7.html#exploratory-visualizations",
    "title": "Challenge 7: AirBnB Visualizations",
    "section": "Exploratory visualizations",
    "text": "Exploratory visualizations\nBefore I create my multi-dimensional visualizations, I want to explore a few aspects of the data through one-dimensional visuals. I’m interested in seeing the relative number of AirBnB listings by borough. I will create a treemap to show the relative proportions of AirBnB offerings for each borough.\n\n# Package\nlibrary(treemapify)\nlibrary(RColorBrewer)\n# Plot\nggplot(AB_NYC_2019 %>%\n           count(neighbourhood_group),\n            aes(fill = neighbourhood_group,\n                area = n,\n                label = n)) +\n  geom_treemap() + \n  geom_treemap_text(colour = \"black\",\n                    place = \"centre\") +\n  labs(title = \"Total AirBnB Listings in NYC Boroughs\",\n       subtitle = \"Manhattan, Brooklyn lead in AirBnB listings in NYC\", \n       fill = \"Borough\") + \n  theme(legend.position = \"left\") +\n  scale_fill_brewer(palette = \"Set2\")\n\n\n\n\nThe treemap above shows that Staten Island has the least AirBnB listings in the 2019 data set by far. Manhattan and Brooklyn take the largest - and almost equal - number of listings.\nI also want to see the distribution of the 3 different room types. I will use another treemap, since I’m looking for a similar type of information.\n\nggplot(AB_NYC_2019 %>%\n           count(room_type),\n            aes(fill = room_type,\n                area = n,\n                label = n)) +\n  geom_treemap() + \n  geom_treemap_text(colour = \"white\",\n                    place = \"centre\") +\n  labs(title = \"Total NYC AirBnB Listings by Type\",\n       subtitle = \"Entire-Home Listings & private rooms rule NYC AirBnBs\", \n       fill = \"Room Type\") + \n  theme(legend.position = \"left\") +\n  scale_fill_brewer(palette = \"Dark2\")\n\n\n\n\nThis treemap shows how few Shared Room types of AirBnBs are represented in the 2019 NYC data. Entire-home AirBnBs are the most common type, but there are also many private rooms."
  },
  {
    "objectID": "posts/TeresaLardo_Challenge7.html#visualization-with-multiple-dimensions",
    "href": "posts/TeresaLardo_Challenge7.html#visualization-with-multiple-dimensions",
    "title": "Challenge 7: AirBnB Visualizations",
    "section": "Visualization with Multiple Dimensions",
    "text": "Visualization with Multiple Dimensions\n\nPrice By Room Type\nI’m curious about how the AirBnBs are generally priced by hosts who have different numbers of total listings. I’m also interested in distinguishing the different room types to see if certain types of rooms tend to be cheaper or more expensive overall. I will use a simple scatterplot where each listing is set to a particular color based on its room type.\n\nggplot(AB_NYC_2019, aes(x=calculated_host_listings_count, y=price)) +\n  geom_point(aes(color=room_type)) + \n  labs(\n    title = \"NYC AirBNB prices sky high even amongst humbler hosts\",\n    x = \"Number of Listings From Host\",\n    y = \"Price of AirBNB ($USD)\", \n    caption = \"Data from InsideAirbnb.com\",\n    color = \"Room Type\") +\n  scale_color_manual(values=c(\"navy\", \"deeppink\", \"green\")) \n\n\n\n\nFrom this visualization, I can see that most of the listings in our set are run by hosts who have fewer than 50 total listings. Even among the listings from the humbler hosts who only offer a single room, the price can be very high. I can also see that Shared Rooms are less represented in the data set than the other two room types.\nI’d like to “zoom in” on this graph to focus on the listings for hosts with 50 or fewer AirBnB properties:\n\nggplot(AB_NYC_2019 %>% \n         filter(calculated_host_listings_count <= 50), aes(x=calculated_host_listings_count, y=price)) +\n  geom_point(aes(color=room_type)) + \n  labs(\n    title = \"Hosts with more properties offer lower-priced NYC AirBnBs\",\n    x = \"Number of Listings From Host\",\n    y = \"Price of AirBNB ($USD)\", \n    caption = \"Data from InsideAirbnb.com\",\n    color = \"Room Type\") +\n  scale_color_manual(values=c(\"navy\", \"deeppink\", \"green\")) \n\n\n\n\n\n\nReviews by Boroughs\nWhich borough and room type gets the most conversation on AirBnB? I will use a bar chart to separate our data first by borough and then separate the borough data into the 3 different room types.\n\nggplot(AB_NYC_2019, aes(fill=room_type, x=neighbourhood_group, y=number_of_reviews)) +\n  geom_bar(position=\"dodge\", stat = \"identity\") +\n  labs(\n    title = \"AirBnBs in Queens get the most reviews\",\n    x = \"NYC Borough\",\n    y = \"Number of Reviews\",\n    fill = \"Room Type\", \n    caption = \"Data from InsideAirbnb.com\"\n  ) \n\n\n\n\nThis visualization shows that, regardless of borough, private rooms tend to receive the most reviews. The only borough where private room reviews do not top the other room types is Brooklyn, where Entire Home-style AirBnBs just barely take the top spot of total reviews. Overall, private rooms in Queens garner the most reviews, with private rooms in Manhattan pulling in a close second. Shared rooms in Staten Island get the least reviews, which makes sense as Staten Island is the borough with the least AirBnB listings by far, and shared rooms are the least represented type of AirBnB offerings."
  },
  {
    "objectID": "posts/TeresaLardo_FinalProjectProposal.html",
    "href": "posts/TeresaLardo_FinalProjectProposal.html",
    "title": "Final Project Assignment#1: Teresa Lardo",
    "section": "",
    "text": "library(tidyverse)\n\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)"
  },
  {
    "objectID": "posts/TeresaLardo_FinalProjectProposal.html#part-1.-introduction",
    "href": "posts/TeresaLardo_FinalProjectProposal.html#part-1.-introduction",
    "title": "Final Project Assignment#1: Teresa Lardo",
    "section": "Part 1. Introduction",
    "text": "Part 1. Introduction\n\nDataset\nFor my final project, I want to work with a data set on Bigfoot reports (“reports” includes direct sightings of or encounters with a creature purported to be Bigfoot, vocalizations thought to be those of a Sasquatch, and discoveries of a Bigfoot-like footprint). This data set describes just over 5000 Bigfoot reports within the continental United States dated from November 1869 to November 2021. The data on Bigfoot sightings is largely self-reported, though some of the earlier reports are taken from newspaper reports.\nThe report data comes from The Bigfoot Field Researchers Organization, or BFRO, and supplemental data on weather and environmental conditions were added from Dark Sky API. The geocoded and weather-enhanced data set I’m using comes courtesy of Tim Renner.\n\n\nQuestions\nWith this data set, I want to explore the relationships between types of reports in different locations and environmental conditions over time:\n\nHow have the amount of Bigfoot reports in different states & geographic regions fluctuated over time? (For example, have sightings in New England increased notably since the 1970s? Was there a spike in reports from Texas in the mid-90s?)\nDo sightings or reports of vocalizations correspond strongly with a specific moon phase?\nAre Class A reports more likely to correspond with clear weather conditions, and do Class B reports correspond to foggy weather, low visibility?"
  },
  {
    "objectID": "posts/TeresaLardo_FinalProjectProposal.html#part-2.-describe-the-data-set",
    "href": "posts/TeresaLardo_FinalProjectProposal.html#part-2.-describe-the-data-set",
    "title": "Final Project Assignment#1: Teresa Lardo",
    "section": "Part 2. Describe the data set",
    "text": "Part 2. Describe the data set\n\nlibrary(readr)\nlibrary(dplyr)\nbfro <- read_csv(\"TeresaLardo_FinalProjectData/bfro_reports_geocoded.csv\", col_types = cols(number = col_skip()))\n\n# Rearrange order of rows for my personal sanity\nbfro <- bfro %>% \n  select(index, date, title, state, county, classification, everything())\n\nhead(bfro)\n\n\n\n  \n\n\n\nIn reading in the csv of the data set, I have opted to remove a variable that simply describes the number of the report in the BFRO system.\n\ndim(bfro)\n\n[1] 5021   28\n\n\n\ncolnames(bfro)\n\n [1] \"index\"              \"date\"               \"title\"             \n [4] \"state\"              \"county\"             \"classification\"    \n [7] \"observed\"           \"location_details\"   \"season\"            \n[10] \"latitude\"           \"longitude\"          \"geohash\"           \n[13] \"temperature_high\"   \"temperature_mid\"    \"temperature_low\"   \n[16] \"dew_point\"          \"humidity\"           \"cloud_cover\"       \n[19] \"moon_phase\"         \"precip_intensity\"   \"precip_probability\"\n[22] \"precip_type\"        \"pressure\"           \"summary\"           \n[25] \"uv_index\"           \"visibility\"         \"wind_bearing\"      \n[28] \"wind_speed\"        \n\n\n\nunique(bfro$season)\n\n[1] \"Summer\"  \"Fall\"    \"Spring\"  \"Winter\"  \"Unknown\"\n\nlength(unique(bfro$state))\n\n[1] 49\n\nunique(bfro$classification)\n\n[1] \"Class B\" \"Class A\" \"Class C\"\n\n\n\nSummary Statistics\nThe dataset includes many variables about environmental conditions for the reports which have specific dates. I would like to concentrate on the following variables: cloud cover, visibility, temperature (high, low, and mid), and moon phase.\n\nlibrary(summarytools)\nbfro_stats <- bfro %>%\n  select(moon_phase, cloud_cover, temperature_high, temperature_mid, temperature_low, visibility) %>%\n  drop_na()\n\ndescr(bfro_stats)\n\nDescriptive Statistics  \nbfro_stats  \nN: 2859  \n\n                    cloud_cover   moon_phase   temperature_high   temperature_low   temperature_mid\n----------------- ------------- ------------ ------------------ ----------------- -----------------\n             Mean          0.43         0.50              67.14             48.83             57.99\n          Std.Dev          0.33         0.29              17.95             16.12             16.54\n              Min          0.00         0.00              -0.62            -22.78             -8.46\n               Q1          0.12         0.25              55.17             37.60             46.80\n           Median          0.39         0.49              70.01             49.70             59.58\n               Q3          0.72         0.75              81.23             61.10             70.66\n              Max          1.00         1.00             106.51             84.34             94.03\n              MAD          0.43         0.37              18.71             17.45             17.69\n              IQR          0.60         0.50              26.06             23.49             23.86\n               CV          0.77         0.58               0.27              0.33              0.29\n         Skewness          0.26         0.00              -0.57             -0.42             -0.52\n      SE.Skewness          0.05         0.05               0.05              0.05              0.05\n         Kurtosis         -1.26        -1.20              -0.16             -0.02             -0.06\n          N.Valid       2859.00      2859.00            2859.00           2859.00           2859.00\n        Pct.Valid        100.00       100.00             100.00            100.00            100.00\n\nTable: Table continues below\n\n \n\n                    visibility\n----------------- ------------\n             Mean         8.53\n          Std.Dev         2.01\n              Min         0.74\n               Q1         7.71\n           Median         9.46\n               Q3        10.00\n              Max        10.00\n              MAD         0.80\n              IQR         2.29\n               CV         0.24\n         Skewness        -1.70\n      SE.Skewness         0.05\n         Kurtosis         2.46\n          N.Valid      2859.00\n        Pct.Valid       100.00\n\n\n\n\nWhat’s In This Dataset?\nA case in this dataset is a Bigfoot report, including sightings, vocalizations, and footprints. There are over 5,000 cases in this set, and the dataset includes:\n\ndescriptions of the events of the encounter,\nthe date & season of the encounter,\nthe location (including state, county, latitude, longitude, geohash, and details describing the specific location such as “near the summit of Mt. Mitchell” or “north of Highway 285”),\ntitle of the report,\nclassification of the sighting (relating to the circumstantial potential for misinterpretation of the observation). Class A denotes to a very low potential for misinterpretation, Class B denotes a greater potential for misinterpretation or misidentification such as in the case of sounds heard but no clear view of a creature, and Class C denotes a high potential for inaccuracy due to being second-hand reports or having untraceable sources),\nand environmental conditions for reports with specified dates, including temperature (high, low, mid), dew point, humidity, cloud cover, moon phase, precipitation (type, probability & intensity), atmospheric pressure, UV index, wind bearing & wind speed, visibility, and a textual summary of the weather conditions of the day in the report’s location.\n\nI plan to focus on the environmental variables of temperature, cloud cover, visibility, and moon phase."
  },
  {
    "objectID": "posts/TeresaLardo_FinalProjectProposal.html#the-tentative-plan-for-visualization",
    "href": "posts/TeresaLardo_FinalProjectProposal.html#the-tentative-plan-for-visualization",
    "title": "Final Project Assignment#1: Teresa Lardo",
    "section": "3. The Tentative Plan for Visualization",
    "text": "3. The Tentative Plan for Visualization\nIn order to explore the question of changes in amount of reports by state and region over time, I plan to mutate the data to create a “Region” variable to better chunk together the geographic data, and then create a time series visualization for the different regions. From there, I can hone in on any regional spikes in activity and investigate the activity at the state level (for states in that region). I want to also look into the details on creating a choropleth map and see if I can integrate an animated time series element into that. I have created some maps on ArcGIS with this data set before, and I think a choropleth map would be a great way to show which areas “light up” with activity within a given timespan.\nTo explore the question of moon phase correspondence, I can start with a basic scatterplot. I would like to use string searching to detect which reports are visual vs. auditory and categorize the reports of vocalizations separately from the visual sightings, and use color to distinguish these two categories on the moon phase scatterplot.\nTo explore the question of Class A & B reports and relative visibility, I can again start with a basic scatterplot where Class A & B reports are distinguished by color. This should give a quick sense of any trends by level of visibility for both classifications. I would also like to dig into the weather details in the “Summary” variable, such as searching for words like “fog” and “foggy” versus “clear,” and see which classes of reports show up most for reports with these weather descriptions. This will also likely be taken from the subset of visual sightings instead of from all reports.\n\nCreating a Region Column\n\n# Creating separate vectors for each region\nPacific <- c(\"California\", \"Oregon\", \"Washington\", \"Alaska\")\nMountain <- c(\"Nevada\", \"Arizona\", \"New Mexico\", \"Colorado\", \"Utah\", \"Idaho\", \"Montana\", \"Wyoming\")\nWest_North_Central <- c(\"Minnesota\", \"North Dakota\", \"South Dakota\", \"Iowa\", \"Nebraska\", \"Kansas\", \"Missouri\")\nWest_South_Central <- c(\"Texas\", \"Oklahoma\", \"Louisiana\", \"Arkansas\")\nEast_North_Central <- c(\"Ohio\", \"Wisconsin\", \"Michigan\", \"Illinois\", \"Indiana\")\nEast_South_Central <- c(\"Alabama\", \"Kentucky\", \"Tennessee\", \"Mississippi\")\nSouth_Atlantic <- c(\"Florida\", \"Georgia\", \"South Carolina\", \"North Carolina\", \"Virginia\", \"West Virginia\", \"Maryland\", \"Delaware\")\nMid_Atlantic <- c(\"Pennsylvania\", \"New York\", \"New Jersey\")\nNew_England <- c(\"Connecticut\", \"Rhode Island\", \"Massachusetts\", 'Vermont', \"New Hampshire\", \"Maine\")\n\n# Mutating new column using the vectors above\nbfro <- bfro %>%\n  mutate(\n    Region = case_when(state %in% Pacific ~ \"Pacific\",\n                       state %in% Mountain ~ \"Mountain\",\n                       state %in% West_North_Central ~ \"West North Central\",\n                       state %in% West_South_Central ~ \"West South Central\",\n                       state %in% East_North_Central ~ \"East North Central\",\n                       state %in% East_South_Central ~ \"East South Central\",\n                       state %in% South_Atlantic ~ \"South Atlantic\",\n                       state %in% Mid_Atlantic ~ \"Mid-Atlantic\",\n                       state %in% New_England ~ \"New England\")\n  )\n\nLet’s do a quick sanity check on that new column:\n\n# Select the state and Region columns from the dataset and look at a sample with head()\nbfro %>% \n  select(state, Region) %>%\n  head(15)\n\n\n\n  \n\n\n\nOkay, good - this sample of the first 15 values of the state & Region columns indicate that the states have been categorized into their correct regions."
  }
]